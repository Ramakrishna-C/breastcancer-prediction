{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ashwin/Padhai/Projects/RKT_BC\n",
      "/Users/ashwin/Padhai/Projects/RKT_BC/US_Dataset_BUSI\n"
     ]
    }
   ],
   "source": [
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "\n",
    "dataset_path = os.path.join(current_working_directory,\"US_Dataset_BUSI\")\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure that the image is loaded as grayscale\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Adjust for grayscale images\n",
    "])\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.Lambda(lambda x: x + 0.1 * torch.randn_like(x) if isinstance(x, torch.Tensor) else x),  # Add random noise directly to the image tensor\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "def load_and_preprocess_image(image_path, apply_augmentation=False):\n",
    "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    transform = augmentation_transform if apply_augmentation else original_transform\n",
    "    img_tensor = transform(img)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for class_name in ['benign','malignant']:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "\n",
    "    image_files = os.listdir(class_path)\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(class_path, image_file)\n",
    "        if \"mask\" in image_file:\n",
    "            continue\n",
    "        original_img_data = load_and_preprocess_image(image_path, apply_augmentation=False)\n",
    "        augmented_img_data = load_and_preprocess_image(image_path, apply_augmentation=True)\n",
    "        data.append(original_img_data)\n",
    "        data.append(augmented_img_data)\n",
    "\n",
    "        label = 0 if class_name == \"benign\" else 1\n",
    "        labels.extend([label,label])\n",
    "\n",
    "data = torch.stack(data)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "df = pd.DataFrame({\"ImageTensor\": list(data), \"Class\": labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageTensor</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[tensor(-0.9534), tensor(0.0056), tensor(0.0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[tensor(-0.9877), tensor(-1.0219), tensor(-1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[tensor(-1.6042), tensor(-1.2959), tensor(0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[tensor(-2.1179), tensor(-2.1179), tensor(-2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[tensor(-1.5357), tensor(-0.1143), tensor(-0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>[[[tensor(-2.1008), tensor(-2.1008), tensor(-2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>[[[tensor(-1.6727), tensor(0.3309), tensor(-1....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>[[[tensor(-2.0494), tensor(-2.0494), tensor(-2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>[[[tensor(-2.0494), tensor(-2.0323), tensor(-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>[[[tensor(-1.8097), tensor(-1.8439), tensor(-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1294 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ImageTensor  Class\n",
       "0     [[[tensor(-0.9534), tensor(0.0056), tensor(0.0...      0\n",
       "1     [[[tensor(-0.9877), tensor(-1.0219), tensor(-1...      0\n",
       "2     [[[tensor(-1.6042), tensor(-1.2959), tensor(0....      0\n",
       "3     [[[tensor(-2.1179), tensor(-2.1179), tensor(-2...      0\n",
       "4     [[[tensor(-1.5357), tensor(-0.1143), tensor(-0...      0\n",
       "...                                                 ...    ...\n",
       "1289  [[[tensor(-2.1008), tensor(-2.1008), tensor(-2...      1\n",
       "1290  [[[tensor(-1.6727), tensor(0.3309), tensor(-1....      1\n",
       "1291  [[[tensor(-2.0494), tensor(-2.0494), tensor(-2...      1\n",
       "1292  [[[tensor(-2.0494), tensor(-2.0323), tensor(-1...      1\n",
       "1293  [[[tensor(-1.8097), tensor(-1.8439), tensor(-1...      1\n",
       "\n",
       "[1294 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1035\n",
      "Validation set: 129\n",
      "Test set: 130\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_df, test_val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Train set:\", len(train_df))\n",
    "print(\"Validation set:\", len(val_df))\n",
    "print(\"Test set:\", len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 28 * 28, 128)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12938433\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]             320\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "         MaxPool2d-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 64, 112, 112]          18,496\n",
      "       BatchNorm2d-5         [-1, 64, 112, 112]             128\n",
      "         MaxPool2d-6           [-1, 64, 56, 56]               0\n",
      "            Conv2d-7          [-1, 128, 56, 56]          73,856\n",
      "       BatchNorm2d-8          [-1, 128, 56, 56]             256\n",
      "         MaxPool2d-9          [-1, 128, 28, 28]               0\n",
      "          Flatten-10               [-1, 100352]               0\n",
      "           Linear-11                  [-1, 128]      12,845,184\n",
      "             ReLU-12                  [-1, 128]               0\n",
      "          Dropout-13                  [-1, 128]               0\n",
      "           Linear-14                    [-1, 1]             129\n",
      "          Sigmoid-15                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 12,938,433\n",
      "Trainable params: 12,938,433\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.00\n",
      "Params size (MB): 49.36\n",
      "Estimated Total Size (MB): 98.55\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'ImageTensor': self.data.iloc[idx]['ImageTensor'], 'Class': self.data.iloc[idx]['Class']}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample['ImageTensor'] = self.transform(sample['ImageTensor'])\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageTensor</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>[[[tensor(-1.4843), tensor(-0.8507), tensor(-0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>[[[tensor(-0.7822), tensor(-0.0287), tensor(-0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>[[[tensor(-2.1179), tensor(-1.7925), tensor(-1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>[[[tensor(-2.1179), tensor(-2.1179), tensor(-2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>[[[tensor(-1.9809), tensor(-1.9809), tensor(-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>[[[tensor(-2.0837), tensor(-2.0494), tensor(-1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>[[[tensor(0.7591), tensor(0.7248), tensor(-0.6...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>[[[tensor(-0.4568), tensor(0.6392), tensor(-1....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>[[[tensor(-2.1179), tensor(-2.1179), tensor(-2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>[[[tensor(-1.7412), tensor(-1.7412), tensor(-1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1035 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ImageTensor  Class\n",
       "1068  [[[tensor(-1.4843), tensor(-0.8507), tensor(-0...      0\n",
       "967   [[[tensor(-0.7822), tensor(-0.0287), tensor(-0...      0\n",
       "803   [[[tensor(-2.1179), tensor(-1.7925), tensor(-1...      0\n",
       "339   [[[tensor(-2.1179), tensor(-2.1179), tensor(-2...      0\n",
       "667   [[[tensor(-1.9809), tensor(-1.9809), tensor(-1...      1\n",
       "...                                                 ...    ...\n",
       "1044  [[[tensor(-2.0837), tensor(-2.0494), tensor(-1...      1\n",
       "1095  [[[tensor(0.7591), tensor(0.7248), tensor(-0.6...      0\n",
       "1130  [[[tensor(-0.4568), tensor(0.6392), tensor(-1....      1\n",
       "860   [[[tensor(-2.1179), tensor(-2.1179), tensor(-2...      0\n",
       "1126  [[[tensor(-1.7412), tensor(-1.7412), tensor(-1...      0\n",
       "\n",
       "[1035 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_df, transform=None)\n",
    "val_dataset = CustomDataset(val_df, transform=None)\n",
    "test_dataset = CustomDataset(test_df, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40:   0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwin/miniconda3/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py:243: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  if not is_compiling() and torch.has_cuda and torch.cuda.is_available():\n",
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Loss: 0.801282165628491, Training Accuracy:0.6386473429951691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Loss: 0.5507753437215631, Training Accuracy:0.7352657004830918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40, Loss: 0.5287321923357068, Training Accuracy:0.7478260869565218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40, Loss: 0.5009547300410994, Training Accuracy:0.7719806763285024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40, Loss: 0.45228016105565155, Training Accuracy:0.808695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40, Loss: 0.4315922725381273, Training Accuracy:0.8009661835748793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40, Loss: 0.4030494066801938, Training Accuracy:0.8222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40, Loss: 0.3729216212576086, Training Accuracy:0.8357487922705314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40, Loss: 0.3502497203422315, Training Accuracy:0.8521739130434782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40, Loss: 0.2972586563590801, Training Accuracy:0.8792270531400966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40, Loss: 0.2920347330245105, Training Accuracy:0.8782608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40, Loss: 0.2684421959248456, Training Accuracy:0.8927536231884058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40, Loss: 0.23307504753271738, Training Accuracy:0.9033816425120773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40, Loss: 0.2172105980641914, Training Accuracy:0.9169082125603865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40, Loss: 0.1940987663287105, Training Accuracy:0.9314009661835749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40, Loss: 0.20175104904355426, Training Accuracy:0.9198067632850242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40, Loss: 0.1747549386187033, Training Accuracy:0.9371980676328503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40, Loss: 0.1640185725056764, Training Accuracy:0.9371980676328503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40, Loss: 0.16013442476590475, Training Accuracy:0.9371980676328503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40, Loss: 0.1353162960572676, Training Accuracy:0.9545893719806763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40, Loss: 0.13273874692844623, Training Accuracy:0.957487922705314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40, Loss: 0.11863071584340298, Training Accuracy:0.957487922705314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40, Loss: 0.09840559711058934, Training Accuracy:0.9710144927536232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40, Loss: 0.10624502136400252, Training Accuracy:0.9555555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40, Loss: 0.09777636272889195, Training Accuracy:0.9671497584541063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40, Loss: 0.08422581501530879, Training Accuracy:0.978743961352657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40, Loss: 0.09628181819888679, Training Accuracy:0.9652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40, Loss: 0.08215603559757724, Training Accuracy:0.9719806763285024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40, Loss: 0.0731722405462554, Training Accuracy:0.9816425120772947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40, Loss: 0.06145314731155381, Training Accuracy:0.9777777777777777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40, Loss: 0.07875559117757913, Training Accuracy:0.970048309178744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40, Loss: 0.06542524983259765, Training Accuracy:0.9768115942028985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40, Loss: 0.058980065087477364, Training Accuracy:0.978743961352657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40, Loss: 0.06927329623563723, Training Accuracy:0.9758454106280193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40, Loss: 0.059589948392275605, Training Accuracy:0.9748792270531401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40, Loss: 0.06343651997546355, Training Accuracy:0.9758454106280193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40, Loss: 0.05580727984620766, Training Accuracy:0.9835748792270531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40, Loss: 0.05757848300378431, Training Accuracy:0.9806763285024155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40, Loss: 0.053498814051801506, Training Accuracy:0.9835748792270531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Loss: 0.050857672044499355, Training Accuracy:0.9835748792270531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 83.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "num_epochs = 40\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}', leave=False)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        images, labels = batch['ImageTensor'].to(device), batch['Class'].float().unsqueeze(1).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        correct_predictions += torch.sum(predictions == labels).item()\n",
    "        total_samples += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': loss.item()})\n",
    "\n",
    "    training_accuracy = correct_predictions / total_samples\n",
    "    progress_bar.close()\n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Training Accuracy:{training_accuracy}\")\n",
    "\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress_bar = tqdm(val_loader, desc='Validation', leave=False)\n",
    "    for batch in progress_bar:\n",
    "        images, labels = batch['ImageTensor'].to(device), batch['Class'].float().unsqueeze(1).to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 78.46%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_predictions_test = []\n",
    "all_labels_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        images_test, labels_test = batch['ImageTensor'].to(device), batch['Class'].float().unsqueeze(1).to(device)\n",
    "        outputs_test = model(images_test)\n",
    "        \n",
    "        predictions_test = (outputs_test >= 0.5).float()\n",
    "        all_predictions_test.extend(predictions_test.cpu().numpy())\n",
    "        all_labels_test.extend(labels_test.cpu().numpy())\n",
    "\n",
    "accuracy_test = accuracy_score(all_labels_test, all_predictions_test)\n",
    "print(f\"Testing Accuracy: {accuracy_test * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
